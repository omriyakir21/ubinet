{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : support multiple hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from utils import multi_exp_data_to_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesis = 'pesto_protein_scores_ablation'\n",
    "# hypothesis = 'optimizer_batchsize_lr_gridsearch'\n",
    "# hypothesis = 'pts_without_mlp_b'\n",
    "# hypothesis = 'pts_deep_encoder_mlps'\n",
    "hypothesis = 'pts_shallow_encoder_mlps'\n",
    "evaluation_type = 'validation'  # can be train / validation / test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = os.listdir(f'../configurations/data/{hypothesis}')\n",
    "experiments = [e.split('.json')[0] for e in experiments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate over all experiments, per experiment - sort runs by time\n",
    "# Going from most recent to oldest, take the first run of the expeirment that finished running (has inference results over all 5 folds)\n",
    "\n",
    "run_paths = []\n",
    "for experiment in experiments:\n",
    "    try:\n",
    "        experiment_runs = os.listdir(f'../results/patch_to_score/hypotheses/{hypothesis}/{experiment}')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    try:\n",
    "        experiment_runs = sorted(experiment_runs, key=lambda x: datetime.strptime(x.split('_')[0], '%Y-%m-%d'), reverse=True)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    experiment_valid_run_found = False\n",
    "    for updated_experiment_run in experiment_runs:\n",
    "        run_path = f'{hypothesis}/{experiment}/{updated_experiment_run}'\n",
    "        if 'fold_4' in os.listdir(f'../results/patch_to_score/hypotheses/{run_path}'):\n",
    "            run_paths.append(run_path)\n",
    "            experiment_valid_run_found = True\n",
    "            break\n",
    "    if not experiment_valid_run_found:\n",
    "        print(f'experiment: {experiment} didnt finish, skipping')\n",
    "len(run_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_paths = [f'../results/patch_to_score/hypotheses/{path}' for path in run_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 15.64it/s]\n"
     ]
    }
   ],
   "source": [
    "multi_exp_data = dict()\n",
    "for base_path in tqdm(base_paths):\n",
    "    exp_data = []\n",
    "    exp_name = base_path.split('/')[-2]\n",
    "    for fold in range(5):\n",
    "        try:\n",
    "            fold_labels = np.load(os.path.join(base_path, f'fold_{fold}', evaluation_type, 'labels.npy'))\n",
    "            fold_predictions = np.load(os.path.join(base_path, f'fold_{fold}', evaluation_type, 'predictions.npy'))[:, 0]\n",
    "            exp_data.append(np.stack([fold_labels, fold_predictions]))\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    multi_exp_data[exp_name] = exp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def name_modification(name: str) -> str:\n",
    "#     res = name.split('_')\n",
    "#     res = f'{res[1]}_{res[2]}_{res[3]}_{res[4]}_{res[6]}_{res[7]}_{res[8]}_{res[9]}_{res[11]}_{res[13]}_{res[14].split(\"-\")[0]}_{res[17]}_{res[19]}_{res[20].split(\"-\")[0]}'\n",
    "#     return res\n",
    "\n",
    "def name_modification(name: str) -> str:\n",
    "    res = name.replace('hidden_sizes_mlp_', '')\n",
    "    res = res.replace('hidden_sizes_mlp_', '')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_multi_exp_data = deepcopy(multi_exp_data)\n",
    "filtered_multi_exp_data = {name_modification(exp_name): exp_data for exp_name, exp_data in filtered_multi_exp_data.items()}\n",
    "# filtered_multi_exp_data = {exp_name: exp_data for exp_name, exp_data in filtered_multi_exp_data.items() if ('sgd' not in exp_name and '0.0001' not in exp_name)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing rocs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 43.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding random roc\n",
      "fig update\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fig, exp_to_auc = multi_exp_data_to_fig(filtered_multi_exp_data, \n",
    "                            show_std_in_legend=False, log_scale=True, resolution=1_000)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a_1_1024-512_c_1_512-512', 0.92228904897246),\n",
       " ('a_1_512-512_c_1_512-512', 0.9212891431788217),\n",
       " ('a_1_512-512_c_2_512-512', 0.9212478760137668),\n",
       " ('a_1_1024-512_c_1_1024-512', 0.9211362445288852),\n",
       " ('a_1_1024-512_c_2_512-512', 0.9211086808563111),\n",
       " ('a_1_512-512_c_1_1024-512', 0.9207519339192733),\n",
       " ('a_2_512-512_c_1_512-512', 0.9198951738338916),\n",
       " ('a_2_512-512_c_2_512-512', 0.9198198586030341),\n",
       " ('a_2_512-512_c_1_1024-512', 0.9191034937188596)]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_experiments = sorted(exp_to_auc.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_experiments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ubinet-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
