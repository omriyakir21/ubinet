{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6d31464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 15:49:29.261001: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-09 15:49:29.367898: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-09 15:49:35.312404: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/iscb/wolfson/doririmon/anaconda3/envs/ubinet-gpu/lib\n",
      "2025-04-09 15:49:35.312508: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/iscb/wolfson/doririmon/anaconda3/envs/ubinet-gpu/lib\n",
      "2025-04-09 15:49:35.312518: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f7ae7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb512325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 15:49:48.620986: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-04-09 15:49:48.622130: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-04-09 15:49:48.623245: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-04-09 15:49:48.624366: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-04-09 15:49:48.625591: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-04-09 15:49:48.626718: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-04-09 15:49:48.627844: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-04-09 15:49:48.628972: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n"
     ]
    }
   ],
   "source": [
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7751d25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example input\n",
    "# inputs = tf.keras.Input(shape=(11,))\n",
    "# x = tf.keras.layers.Dense(1024, activation='relu')(inputs)\n",
    "# x = TransformerEncoderMLP(hidden_units=(1024, 1024), dropout_rate=0.2)(x)\n",
    "# model = tf.keras.Model(inputs, x)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a6788577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(tf.random.uniform((10, 11)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d52445e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def bootstrap_pts_encoder_mlps(hidden_sizes_mlp_a: List[Tuple[int, int]], mlp_a_dropout_rate: float,\n",
    "#                                hidden_sizes_mlp_c: List[Tuple[int, int]], mlp_c_dropout_rate: float,\n",
    "#                                activation: str, input_shape: Tuple[int, int],\n",
    "#                                max_number_of_patches: int) -> tf.keras.models.Model:\n",
    "#     model = build_model(hidden_sizes_mlp_a, mlp_a_dropout_rate,\n",
    "#                                          hidden_sizes_mlp_c, mlp_c_dropout_rate,\n",
    "#                                          activation, input_shape, max_number_of_patches)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2c444d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31eecd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 15:49:58.295170: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 10, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x72b2edfde140>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_model(\n",
    "    hidden_sizes_mlp_a=[(1024, 1024), (1024, 1024)],\n",
    "    mlp_a_dropout_rate=0.2,\n",
    "    hidden_sizes_mlp_c=[(1024, 1024), (1024, 1024)],\n",
    "    mlp_c_dropout_rate=0.2,\n",
    "    activation='relu',\n",
    "    input_shape=[10, 9],\n",
    "    max_number_of_patches=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c4a89af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = bootstrap_pts_encoder_mlps(\n",
    "#     hidden_sizes_mlp_a=[(1024, 1024), (1024, 1024)],\n",
    "#     mlp_a_dropout_rate=0.2,\n",
    "#     hidden_sizes_mlp_c=[(1024, 1024), (1024, 1024)],\n",
    "#     mlp_c_dropout_rate=0.2,\n",
    "#     activation='relu',\n",
    "#     input_shape=[10, 9],\n",
    "#     max_number_of_patches=10\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5e5e2bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(tf.random.uniform((20, 10, 9), minval=0, maxval=1),\n",
    "#       tf.random.uniform((20, 1), minval=0, maxval=1),\n",
    "#       tf.one_hot(tf.random.uniform((20,), minval=0, maxval=10), depth=11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2633643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ubinet-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
