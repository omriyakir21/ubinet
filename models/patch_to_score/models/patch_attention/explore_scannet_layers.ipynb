{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81a2a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-16 04:06:21.152222: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-16 04:06:21.261787: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-16 04:06:26.017062: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/iscb/wolfson/doririmon/anaconda3/envs/ubinet-gpu/lib\n",
      "2025-08-16 04:06:26.017193: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/iscb/wolfson/doririmon/anaconda3/envs/ubinet-gpu/lib\n",
      "2025-08-16 04:06:26.017205: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2025-08-16 04:06:37.935658: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-08-16 04:06:37.936912: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-08-16 04:06:37.938183: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-08-16 04:06:37.939430: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-08-16 04:06:37.941774: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-08-16 04:06:37.944544: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-08-16 04:06:37.945658: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-08-16 04:06:37.947412: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "from plotly import express as px\n",
    "from typing import List, Tuple\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fd4b8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f0fc6b",
   "metadata": {},
   "source": [
    "## load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eeb3cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-16 04:06:38.267913: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "with open('/home/iscb/wolfson/doririmon/home/order/ubinet/repo/ubinet/datasets/patch_to_score/data_for_training/03_04_with_pesto_and_coord/folds_training_dicts.pkl', 'rb') as f:\n",
    "    folds_training_dicts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d4cc814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sizes_train', 'components_train', 'num_patches_train', 'uniprots_train', 'labels_train', 'sizes_validation', 'components_validation', 'num_patches_validation', 'uniprots_validation', 'labels_validation', 'sizes_test', 'components_test', 'num_patches_test', 'uniprots_test', 'labels_test', 'coordinates_train', 'coordinates_validation', 'coordinates_test'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold = folds_training_dicts[0]\n",
    "fold.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "852264d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = fold['components_train']\n",
    "coordinates = fold['coordinates_train']\n",
    "size_value = fold['sizes_train']\n",
    "n_patches_hot_encoded_value = fold['num_patches_train']\n",
    "max_number_of_patches = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f61454a",
   "metadata": {},
   "source": [
    "## debug pairwise transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b85e455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f119781d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing projection for skip connection: 11 -> 256\n",
      "initializing projection for skip connection: None -> 256\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer \"transformer_encoder_mlp_2\" (type TransformerEncoderMLP).\n\nin user code:\n\n    File \"/home/iscb/wolfson/doririmon/home/order/ubinet/repo/ubinet/models/patch_to_score/models/patch_attention/../../../../models/patch_to_score/models/modules/transformer_encoder_mlp.py\", line 44, in call  *\n        x = self.dense1(inputs)\n    File \"/home/iscb/wolfson/doririmon/anaconda3/envs/ubinet-gpu/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/iscb/wolfson/doririmon/anaconda3/envs/ubinet-gpu/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 213, in assert_input_compatibility\n        raise TypeError(f\"Inputs to a layer should be tensors. Got: {x}\")\n\n    TypeError: Inputs to a layer should be tensors. Got: None\n\n\nCall arguments received by layer \"transformer_encoder_mlp_2\" (type TransformerEncoderMLP):\n  • inputs=None\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_mlp_hidden_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeatures_mlp_dropout_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_mlp_hidden_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_mlp_dropout_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mlp_hidden_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mlp_dropout_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_number_of_patches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_dimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgaussian_xrange\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpairs_channel_dimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_pair_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/home/order/ubinet/repo/ubinet/models/patch_to_score/models/patch_attention/model.py:126\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(features_mlp_hidden_sizes, features_mlp_dropout_rate, output_mlp_hidden_sizes, output_mlp_dropout_rate, attention_mlp_hidden_sizes, attention_mlp_dropout_rate, activation, input_shape, max_number_of_patches, attention_dimension, pairs_channel_dimension, gaussian_xrange, num_heads, use_pair_bias)\u001b[0m\n\u001b[1;32m    122\u001b[0m attention_mlp_output \u001b[38;5;241m=\u001b[39m apply_mlps(\n\u001b[1;32m    123\u001b[0m     attention_output, attention_mlp_hidden_sizes, attention_mlp_dropout_rate, activation)\n\u001b[1;32m    124\u001b[0m global_pooling_output \u001b[38;5;241m=\u001b[39m GlobalSumPooling(\n\u001b[1;32m    125\u001b[0m     data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannels_last\u001b[39m\u001b[38;5;124m'\u001b[39m)(attention_mlp_output)\n\u001b[0;32m--> 126\u001b[0m output_mlp_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_mlps\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobal_pooling_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_mlp_hidden_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_mlp_dropout_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)(output_mlp_output)\n\u001b[1;32m    129\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m    130\u001b[0m                        input_data, coordinates, size_value, n_patches_hot_encoded_value], outputs\u001b[38;5;241m=\u001b[39moutput)\n",
      "File \u001b[0;32m~/home/order/ubinet/repo/ubinet/models/patch_to_score/models/patch_attention/model.py:43\u001b[0m, in \u001b[0;36mapply_mlps\u001b[0;34m(inputs, hidden_sizes, dropout_rate, activation)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hidden_size \u001b[38;5;129;01min\u001b[39;00m hidden_sizes:\n\u001b[1;32m     41\u001b[0m     mlp \u001b[38;5;241m=\u001b[39m TransformerEncoderMLP(\n\u001b[1;32m     42\u001b[0m         hidden_units\u001b[38;5;241m=\u001b[39mhidden_size, dropout_rate\u001b[38;5;241m=\u001b[39mdropout_rate, activation\u001b[38;5;241m=\u001b[39mactivation)\n\u001b[0;32m---> 43\u001b[0m     current_output \u001b[38;5;241m=\u001b[39m \u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     current_output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mReLU()(\n\u001b[1;32m     45\u001b[0m         current_output)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m current_output\n",
      "File \u001b[0;32m~/anaconda3/envs/ubinet-gpu/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filell39eyx4.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m      8\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 10\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mactivation_layer, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdropout1, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(training)), fscope)\n",
      "\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer \"transformer_encoder_mlp_2\" (type TransformerEncoderMLP).\n\nin user code:\n\n    File \"/home/iscb/wolfson/doririmon/home/order/ubinet/repo/ubinet/models/patch_to_score/models/patch_attention/../../../../models/patch_to_score/models/modules/transformer_encoder_mlp.py\", line 44, in call  *\n        x = self.dense1(inputs)\n    File \"/home/iscb/wolfson/doririmon/anaconda3/envs/ubinet-gpu/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/iscb/wolfson/doririmon/anaconda3/envs/ubinet-gpu/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 213, in assert_input_compatibility\n        raise TypeError(f\"Inputs to a layer should be tensors. Got: {x}\")\n\n    TypeError: Inputs to a layer should be tensors. Got: None\n\n\nCall arguments received by layer \"transformer_encoder_mlp_2\" (type TransformerEncoderMLP):\n  • inputs=None\n  • training=False\n  • mask=None"
     ]
    }
   ],
   "source": [
    "build_model(features_mlp_hidden_sizes=[[256, 256]],\n",
    "            features_mlp_dropout_rate=0.2,\n",
    "            output_mlp_hidden_sizes=[[256, 256]], output_mlp_dropout_rate=0.2,\n",
    "            attention_mlp_hidden_sizes=[[256, 256]], attention_mlp_dropout_rate=0.2,\n",
    "            activation='relu', input_shape=(10, 9), max_number_of_patches=10, attention_dimension=256,\n",
    "            gaussian_xrange=(0, 200),\n",
    "            pairs_channel_dimension=256, num_heads=8, use_pair_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa91450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import create_masked_inputs\n",
    "\n",
    "features, pairwise_distances = create_masked_inputs(\n",
    "        input_data, coordinates, size_value, n_patches_hot_encoded_value, max_number_of_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f894c2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.imshow(pairwise_distances[0][:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36198fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.imshow(pairwise_distances._keras_mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ed17e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.patch_to_score.models.modules.scannet_layers import GaussianKernel, MaskedDense, initialize_GaussianKernel, initialize_GaussianKernelRandom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bb50d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat_distances = pairwise_distances.numpy().flatten()\n",
    "# flat_distances = flat_distances[flat_distances != 0]\n",
    "# px.histogram(flat_distances[::10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb33dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "num_heads = 1\n",
    "# initial_values = initialize_GaussianKernelRandom([[0, 200]], N, 'diag')\n",
    "initial_values = [np.array([np.linspace(0, 200, N)]), np.array([[(200 / (N/ 4)) for _ in range(N)]])]\n",
    "kernel = GaussianKernel(N, initial_values, 'diag')\n",
    "\n",
    "layer_norm = tf.keras.layers.LayerNormalization()\n",
    "dense = MaskedDense(num_heads, use_bias=False)\n",
    "\n",
    "after_kernel = kernel(pairwise_distances)\n",
    "after_layer_norm = layer_norm(after_kernel)\n",
    "after_dense = dense(after_layer_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da4ebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pairwise_distances.numpy().flatten()\n",
    "ys = [after_kernel[:, :, :, i].numpy().flatten() for i in range(N)]\n",
    "px.scatter(x=x[::1111], y=[y[::1111] for y in ys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d5fe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.imshow(pairwise_distances[0][:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6c0664",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(after_dense[0][:, :, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ubinet-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
