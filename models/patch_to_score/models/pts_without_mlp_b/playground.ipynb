{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1fc3c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import tensorflow as tf\n",
    "from utils import GlobalSumPooling\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as kl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2512b1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast_shape(x, max_number_of_patches: int) -> tf.Tensor:\n",
    "    x_expanded = tf.expand_dims(x, axis=1)\n",
    "    x_broadcasted = tf.broadcast_to(x_expanded, [tf.shape(x)[0], max_number_of_patches, tf.shape(x)[-1]])\n",
    "    return x_broadcasted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6eda9fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(m_a: int, m_c: int, n_layers: int, input_shape: Tuple[int, int],\n",
    "                max_number_of_patches: int) -> tf.keras.models.Model:\n",
    "    '''\n",
    "    :param m_a: size of the hidden layers in the MLP of the components\n",
    "    :param m_c: size of the hidden layers in the MLP of the concatenated global sum output and size + n_patches MLP output\n",
    "    :param n_layers: number of layers in each of the MLPs\n",
    "    :param input_shape: shape of the input data (number of patches, number of features)\n",
    "    :param max_number_of_patches: maximum number of patches\n",
    "    :return: a Keras model\n",
    "    '''\n",
    "    input_data = tf.keras.Input(shape=input_shape, name='patches_input')\n",
    "    size_value = tf.keras.Input(shape=(1,), name='extra_value_input')\n",
    "    n_patches_hot_encoded_value = tf.keras.Input(\n",
    "        shape=(max_number_of_patches + 1,), name='hot_encoded_value_input')\n",
    "    n_patches = tf.argmax(n_patches_hot_encoded_value, axis=1)[..., None]\n",
    "    n_patches = tf.cast(n_patches, tf.float32)\n",
    "    \n",
    "    n_patches_broadcased = broadcast_shape(n_patches, max_number_of_patches)\n",
    "    size_broadcased = broadcast_shape(size_value, max_number_of_patches)\n",
    "    \n",
    "    concat_input_data = tf.keras.layers.Concatenate(axis=-1)([input_data, n_patches_broadcased, size_broadcased])\n",
    "    masked_input = tf.keras.layers.Masking(mask_value=0.0)(concat_input_data)\n",
    "\n",
    "    currentOutput = masked_input\n",
    "    for i in range(n_layers):\n",
    "        dense_output = tf.keras.layers.Dense(\n",
    "            m_a, activation='linear')(currentOutput)\n",
    "        batchNorm = tf.keras.layers.BatchNormalization(\n",
    "            momentum=0.75)(dense_output)\n",
    "        activation = tf.keras.layers.ReLU()(batchNorm)\n",
    "        currentOutput = activation\n",
    "\n",
    "    global_pooling_output = GlobalSumPooling(\n",
    "        data_format='channels_last')(currentOutput)\n",
    "\n",
    "    currentOutput = global_pooling_output\n",
    "    for i in range(n_layers):\n",
    "        dense_output = tf.keras.layers.Dense(\n",
    "            m_c, activation='linear')(currentOutput)\n",
    "        batchNorm = tf.keras.layers.BatchNormalization(\n",
    "            momentum=0.75)(dense_output)\n",
    "        activation = tf.keras.layers.ReLU()(batchNorm)\n",
    "        currentOutput = activation\n",
    "\n",
    "    before_sigmoid_output = currentOutput\n",
    "\n",
    "    output = tf.keras.layers.Dense(\n",
    "        1, activation='sigmoid')(before_sigmoid_output)\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_data, size_value, n_patches_hot_encoded_value], outputs=output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "98bedaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    m_a=128, m_c=64, n_layers=4, input_shape=(10, 9), max_number_of_patches=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7fcb96c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[0.5       ],\n",
       "       [0.67460376]], dtype=float32)>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb314e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 17:07:32.152851: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-04-04 17:07:32.154004: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-04-04 17:07:32.155136: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-04-04 17:07:32.156287: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-04-04 17:07:32.157419: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-04-04 17:07:32.158525: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-04-04 17:07:32.159664: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
      "2025-04-04 17:07:32.160804: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n"
     ]
    }
   ],
   "source": [
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "535e4dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (10, 9)\n",
    "n_layers = 5\n",
    "m_a = 1024\n",
    "m_c = 1024\n",
    "max_number_of_patches = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e919b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = tf.keras.Input(shape=input_shape, name='patches_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "486d9afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 10, 9) dtype=float32 (created by layer 'patches_input')>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5ecbdbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_patches_one_hot = np.zeros((2, max_number_of_patches + 1))\n",
    "n_patches_one_hot[0][0] = 1\n",
    "n_patches_one_hot[1][5] = 1\n",
    "input_example = [tf.zeros((2, 10, 9)), tf.zeros((2, 1)), tf.convert_to_tensor(n_patches_one_hot)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a3955e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_value = tf.keras.Input(shape=(1,), name='extra_value_input')\n",
    "n_patches_hot_encoded_value = tf.keras.Input(\n",
    "    shape=(max_number_of_patches + 1,), name='hot_encoded_value_input')\n",
    "n_patches = tf.argmax(n_patches_hot_encoded_value, axis=1)[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a2d2e343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'extra_value_input')>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0c7815dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1) dtype=int64 (created by layer 'tf.__operators__.getitem_1')>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9a6e78e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 1)\n",
      "(None, None, None)\n",
      "(8, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as kl\n",
    "import numpy as np\n",
    "\n",
    "x = tf.keras.Input([1])\n",
    "y = tf.keras.layers.Reshape([1, 1])(x)  # Need to add empty dims before broadcasting\n",
    "# Retain the batch and depth dimensions, but broadcast along H and W\n",
    "print(y.shape)\n",
    "broadcasted_shape = tf.where([True, False, True],\n",
    "                           tf.shape(y), [0, max_number_of_patches, 0])\n",
    "y = tf.broadcast_to(y, broadcasted_shape)  # Broadcast to shape [None, 10, 1]\n",
    "print(y.shape)\n",
    "\n",
    "model = tf.keras.Model(inputs=x, outputs=y)\n",
    "\n",
    "print(model(np.random.random(size=(8, 1))).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1d4cb7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Example input tensor of shape [None, 1]\n",
    "x = tf.keras.Input(shape=(1,))  # Placeholder for the input\n",
    "\n",
    "# Expand dimensions to [None, 1, 1]\n",
    "x_expanded = tf.expand_dims(x, axis=1)\n",
    "\n",
    "# Broadcast to shape [None, 10, 1]\n",
    "x_broadcasted = tf.broadcast_to(x_expanded, [tf.shape(x)[0], 10, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4f53fef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 10, 1) dtype=float32 (created by layer 'tf.broadcast_to_85')>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_broadcasted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "628d43ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, None, None) dtype=float32 (created by layer 'tf.broadcast_to_78')>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcast_shape(x, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1589be17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55442c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'extra_value_input')>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "41407ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_patches.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679c3488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d0f91f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "891e5353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_patches_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bad6247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_patches = tf.argmax(input_example[-1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5dcece3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 5])>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06270b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'extra_value_input')>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceb7381",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_data = tf.keras.layers.Concatenate()([input_data, size_value, n_patches_hot_encoded_value])\n",
    "masked_input = tf.keras.layers.Masking(mask_value=0.0)(input_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ubinet-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
